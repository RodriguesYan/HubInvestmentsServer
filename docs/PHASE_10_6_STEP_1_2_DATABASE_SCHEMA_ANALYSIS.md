# Phase 10.6 - Step 1.2: Order Management System - Database Schema Analysis

**Date**: November 4, 2025  
**Service**: `hub-order-service`  
**Database**: PostgreSQL  
**Migration Strategy**: Separate Database Per Service

---

## Executive Summary

The Order Management System uses a single `orders` table with 22 columns and 6 indexes. This document analyzes the existing schema, foreign key relationships, and provides a migration strategy for the microservice.

---

## 1. Current Database Schema

### 1.1 Orders Table Structure

```sql
CREATE TABLE orders (
    -- Primary Key
    id UUID PRIMARY KEY,
    
    -- User Reference
    user_id INTEGER NOT NULL REFERENCES users(id),
    
    -- Order Details
    symbol VARCHAR(20) NOT NULL,
    order_type VARCHAR(20) NOT NULL CHECK (order_type IN ('MARKET', 'LIMIT', 'STOP_LOSS', 'STOP_LIMIT')),
    order_side VARCHAR(10) NOT NULL CHECK (order_side IN ('BUY', 'SELL')),
    quantity DECIMAL(18,8) NOT NULL CHECK (quantity > 0),
    price DECIMAL(18,8) CHECK (price > 0),
    
    -- Status and Lifecycle
    status VARCHAR(20) NOT NULL DEFAULT 'PENDING' CHECK (status IN ('PENDING', 'PROCESSING', 'EXECUTED', 'FAILED', 'CANCELLED')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    executed_at TIMESTAMP,
    
    -- Execution Details
    execution_price DECIMAL(18,8),
    market_price_at_submission DECIMAL(18,8),
    market_data_timestamp TIMESTAMP,
    
    -- Error Handling and Retry
    failure_reason TEXT,
    retry_count INTEGER DEFAULT 0,
    
    -- Worker Tracking
    processing_worker_id VARCHAR(50),
    
    -- External Integration
    external_order_id VARCHAR(100)
);
```

### 1.2 Column Details

| Column | Type | Nullable | Default | Description |
|--------|------|----------|---------|-------------|
| `id` | UUID | NO | - | Primary key, generated by application |
| `user_id` | INTEGER | NO | - | Foreign key to `users(id)` |
| `symbol` | VARCHAR(20) | NO | - | Trading symbol (AAPL, GOOGL, etc.) |
| `order_type` | VARCHAR(20) | NO | - | MARKET, LIMIT, STOP_LOSS, STOP_LIMIT |
| `order_side` | VARCHAR(10) | NO | - | BUY or SELL |
| `quantity` | DECIMAL(18,8) | NO | - | Order quantity (must be > 0) |
| `price` | DECIMAL(18,8) | YES | NULL | Limit price (NULL for market orders) |
| `status` | VARCHAR(20) | NO | 'PENDING' | Order status |
| `created_at` | TIMESTAMP | NO | NOW() | Order creation timestamp |
| `updated_at` | TIMESTAMP | NO | NOW() | Last update timestamp (auto-updated) |
| `executed_at` | TIMESTAMP | YES | NULL | Execution timestamp |
| `execution_price` | DECIMAL(18,8) | YES | NULL | Actual execution price |
| `market_price_at_submission` | DECIMAL(18,8) | YES | NULL | Market price when submitted |
| `market_data_timestamp` | TIMESTAMP | YES | NULL | Market data timestamp |
| `failure_reason` | TEXT | YES | NULL | Error message if failed |
| `retry_count` | INTEGER | NO | 0 | Number of retry attempts |
| `processing_worker_id` | VARCHAR(50) | YES | NULL | Worker ID processing the order |
| `external_order_id` | VARCHAR(100) | YES | NULL | External broker order ID |

### 1.3 Constraints

**Check Constraints**:
1. `order_type IN ('MARKET', 'LIMIT', 'STOP_LOSS', 'STOP_LIMIT')`
2. `order_side IN ('BUY', 'SELL')`
3. `quantity > 0`
4. `price > 0` (when not NULL)
5. `status IN ('PENDING', 'PROCESSING', 'EXECUTED', 'FAILED', 'CANCELLED')`

**Foreign Key Constraints**:
1. `user_id REFERENCES users(id)` - Links to user who created the order

### 1.4 Indexes

```sql
-- Single-column indexes
CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_orders_created_at ON orders(created_at DESC);
CREATE INDEX idx_orders_symbol ON orders(symbol);

-- Composite indexes
CREATE INDEX idx_orders_user_status ON orders(user_id, status);
CREATE INDEX idx_orders_symbol_status ON orders(symbol, status);
```

**Index Usage**:
- `idx_orders_user_id` - User order queries (most common)
- `idx_orders_status` - Status-based queries (worker processing)
- `idx_orders_created_at` - Order history (chronological)
- `idx_orders_symbol` - Symbol-based queries (analytics)
- `idx_orders_user_status` - User order filtering by status
- `idx_orders_symbol_status` - Symbol order filtering by status

### 1.5 Triggers

```sql
-- Auto-update updated_at timestamp
CREATE OR REPLACE FUNCTION update_orders_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_orders_updated_at
    BEFORE UPDATE ON orders
    FOR EACH ROW
    EXECUTE FUNCTION update_orders_updated_at();
```

**Purpose**: Automatically update `updated_at` timestamp on every UPDATE operation.

---

## 2. Foreign Key Relationships

### 2.1 Outgoing Foreign Keys (Orders → Other Tables)

**1. orders.user_id → users.id**
- **Relationship**: Many-to-One (Many orders belong to one user)
- **Constraint**: `REFERENCES users(id)`
- **On Delete**: Not specified (default: RESTRICT)
- **Impact**: User deletion would fail if orders exist
- **Migration Impact**: **CRITICAL** - User Service owns `users` table

### 2.2 Incoming Foreign Keys (Other Tables → Orders)

**None identified** - No other tables reference `orders` table.

**Verification Needed**: Check for:
- Audit tables
- Transaction history tables
- Notification tables
- Analytics tables

---

## 3. Data Volume and Growth Analysis

### 3.1 Current Data Volume (Estimated)

**Assumptions**:
- 1,000 active users
- Average 10 orders per user per month
- 6 months of historical data

**Estimated Row Count**: ~60,000 orders

**Storage Size**:
- Row size: ~400 bytes (with indexes)
- Total size: ~24 MB (data) + ~12 MB (indexes) = **~36 MB**

### 3.2 Growth Projections

**Year 1**:
- Orders per month: 10,000
- Total rows: 120,000
- Storage: ~72 MB

**Year 3**:
- Orders per month: 50,000
- Total rows: 1,800,000
- Storage: ~1.08 GB

**Scaling Considerations**:
- Partitioning by `created_at` (monthly partitions)
- Archiving old orders (>1 year) to cold storage
- Read replicas for analytics queries

---

## 4. Migration Strategy

### 4.1 Database Per Service Pattern

**Decision**: ✅ **Separate Database for Order Service**

**Rationale**:
1. **Service Independence**: Order Service can deploy independently
2. **Data Ownership**: Clear ownership of order data
3. **Scaling**: Independent scaling of order database
4. **Failure Isolation**: Order DB failure doesn't affect other services
5. **Performance**: Dedicated resources for high-volume order operations

### 4.2 Database Configuration

**New Database**: `hub_order_service`

**Connection String**:
```
postgresql://hub_order_service_user:password@localhost:5432/hub_order_service?sslmode=require
```

**User Permissions**:
```sql
CREATE DATABASE hub_order_service;
CREATE USER hub_order_service_user WITH PASSWORD 'secure_password';
GRANT ALL PRIVILEGES ON DATABASE hub_order_service TO hub_order_service_user;
```

### 4.3 Schema Migration Plan

**Step 1: Create New Database**
```bash
# Run database setup script
./scripts/setup_database.sh
```

**Step 2: Create Schema**
```sql
-- Copy from database/orders.sql
-- Create orders table with all constraints
-- Create indexes
-- Create triggers
```

**Step 3: Migrate Data**
```sql
-- Copy existing orders from monolith database
INSERT INTO hub_order_service.orders
SELECT * FROM hub_investments.orders;
```

**Step 4: Verify Data Integrity**
```sql
-- Compare row counts
SELECT COUNT(*) FROM hub_investments.orders;
SELECT COUNT(*) FROM hub_order_service.orders;

-- Verify foreign key relationships
SELECT DISTINCT user_id FROM hub_order_service.orders
WHERE user_id NOT IN (SELECT id FROM hub_investments.users);
```

### 4.4 Foreign Key Handling

**Problem**: `orders.user_id` references `users.id` in User Service database

**Solution Options**:

**Option 1: Remove Foreign Key Constraint (RECOMMENDED)**
```sql
-- Remove FK constraint in microservice
ALTER TABLE orders DROP CONSTRAINT orders_user_id_fkey;

-- Add CHECK constraint for data validation
ALTER TABLE orders ADD CONSTRAINT check_user_id_not_null CHECK (user_id IS NOT NULL);
```

**Rationale**:
- Microservices should not have cross-database foreign keys
- User existence validated via User Service API (gRPC)
- Application-level referential integrity

**Option 2: Denormalize User Data**
```sql
-- Add user_email column for reference
ALTER TABLE orders ADD COLUMN user_email VARCHAR(255);
```

**Rationale**:
- Useful for queries without calling User Service
- Trade-off: Data duplication

**Recommendation**: **Option 1** (Remove FK, validate via API)

---

## 5. Data Migration Strategy

### 5.1 Migration Approach

**Strategy**: **Copy-and-Sync**

**Phases**:

**Phase 1: Initial Copy (Pre-Migration)**
```sql
-- Copy all existing orders to new database
INSERT INTO hub_order_service.orders
SELECT * FROM hub_investments.orders;
```

**Phase 2: Dual-Write (During Migration)**
```
1. Monolith writes to both databases (old + new)
2. Microservice reads from new database
3. Verify data consistency
```

**Phase 3: Cutover**
```
1. Stop monolith writes
2. Final sync (copy delta)
3. Switch to microservice
4. Verify no data loss
```

**Phase 4: Cleanup (Post-Migration)**
```sql
-- After 30-day validation period
-- Drop orders table from monolith database
DROP TABLE hub_investments.orders;
```

### 5.2 Data Consistency Validation

**Validation Queries**:

```sql
-- 1. Row count comparison
SELECT 
    (SELECT COUNT(*) FROM hub_investments.orders) AS monolith_count,
    (SELECT COUNT(*) FROM hub_order_service.orders) AS microservice_count;

-- 2. Status distribution
SELECT status, COUNT(*) 
FROM hub_investments.orders 
GROUP BY status 
ORDER BY status;

SELECT status, COUNT(*) 
FROM hub_order_service.orders 
GROUP BY status 
ORDER BY status;

-- 3. User order count
SELECT user_id, COUNT(*) AS order_count
FROM hub_investments.orders
GROUP BY user_id
ORDER BY order_count DESC
LIMIT 10;

SELECT user_id, COUNT(*) AS order_count
FROM hub_order_service.orders
GROUP BY user_id
ORDER BY order_count DESC
LIMIT 10;

-- 4. Latest orders comparison
SELECT id, user_id, symbol, status, created_at
FROM hub_investments.orders
ORDER BY created_at DESC
LIMIT 10;

SELECT id, user_id, symbol, status, created_at
FROM hub_order_service.orders
ORDER BY created_at DESC
LIMIT 10;

-- 5. Checksum comparison (data integrity)
SELECT MD5(CAST(ROW(id, user_id, symbol, status, quantity, price) AS TEXT))
FROM hub_investments.orders
ORDER BY id;

SELECT MD5(CAST(ROW(id, user_id, symbol, status, quantity, price) AS TEXT))
FROM hub_order_service.orders
ORDER BY id;
```

### 5.3 Rollback Plan

**Scenario**: Microservice fails, need to rollback to monolith

**Steps**:
1. Stop microservice
2. Re-enable monolith order endpoints
3. Sync any new orders from microservice → monolith
4. Verify monolith is processing orders correctly
5. Investigate and fix microservice issues

**Rollback Script**:
```sql
-- Copy orders created during microservice operation
INSERT INTO hub_investments.orders
SELECT * FROM hub_order_service.orders
WHERE created_at > '2025-11-04 00:00:00' -- Cutover timestamp
ON CONFLICT (id) DO NOTHING;
```

---

## 6. Performance Optimization

### 6.1 Connection Pooling

**Configuration**:
```yaml
database:
  max_connections: 25
  min_connections: 5
  max_idle_time: 10m
  connection_timeout: 5s
  statement_timeout: 30s
```

**Rationale**:
- 25 connections sufficient for 1000+ orders/minute
- Min 5 connections for low-traffic periods
- 10-minute idle timeout to release unused connections

### 6.2 Query Optimization

**Slow Query Analysis**:
```sql
-- Enable slow query logging
ALTER DATABASE hub_order_service SET log_min_duration_statement = 100;

-- Analyze query performance
EXPLAIN ANALYZE
SELECT * FROM orders
WHERE user_id = 1
ORDER BY created_at DESC
LIMIT 10;
```

**Index Usage**:
```sql
-- Check index usage
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan AS index_scans,
    idx_tup_read AS tuples_read,
    idx_tup_fetch AS tuples_fetched
FROM pg_stat_user_indexes
WHERE tablename = 'orders'
ORDER BY idx_scan DESC;
```

### 6.3 Partitioning Strategy (Future)

**When to Partition**: When table exceeds 1M rows or 1 GB

**Partition Key**: `created_at` (monthly partitions)

**Example**:
```sql
-- Create partitioned table
CREATE TABLE orders (
    -- Same columns as before
) PARTITION BY RANGE (created_at);

-- Create partitions
CREATE TABLE orders_2025_01 PARTITION OF orders
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE orders_2025_02 PARTITION OF orders
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- Auto-create partitions with pg_partman extension
```

---

## 7. Backup and Recovery

### 7.1 Backup Strategy

**Backup Types**:
1. **Full Backup**: Daily at 2 AM UTC
2. **Incremental Backup**: Every 6 hours
3. **Point-in-Time Recovery**: WAL archiving enabled

**Backup Script**:
```bash
#!/bin/bash
# Backup orders database
pg_dump -h localhost -U hub_order_service_user \
    -d hub_order_service \
    -F c -b -v \
    -f /backups/hub_order_service_$(date +%Y%m%d_%H%M%S).backup
```

**Retention Policy**:
- Daily backups: 30 days
- Weekly backups: 12 weeks
- Monthly backups: 12 months

### 7.2 Recovery Procedures

**Scenario 1: Restore from Full Backup**
```bash
pg_restore -h localhost -U hub_order_service_user \
    -d hub_order_service \
    -c -v /backups/hub_order_service_20251104.backup
```

**Scenario 2: Point-in-Time Recovery**
```bash
# Restore base backup
pg_restore -d hub_order_service /backups/base_backup.backup

# Apply WAL logs up to specific timestamp
recovery_target_time = '2025-11-04 12:30:00'
```

---

## 8. Security Considerations

### 8.1 Access Control

**Database User Permissions**:
```sql
-- Application user (read/write)
CREATE USER hub_order_service_user WITH PASSWORD 'secure_password';
GRANT SELECT, INSERT, UPDATE, DELETE ON orders TO hub_order_service_user;

-- Read-only user (analytics)
CREATE USER hub_order_service_readonly WITH PASSWORD 'readonly_password';
GRANT SELECT ON orders TO hub_order_service_readonly;

-- Admin user (schema changes)
CREATE USER hub_order_service_admin WITH PASSWORD 'admin_password';
GRANT ALL PRIVILEGES ON DATABASE hub_order_service TO hub_order_service_admin;
```

### 8.2 Encryption

**Encryption at Rest**:
- PostgreSQL Transparent Data Encryption (TDE)
- Or disk-level encryption (LUKS, dm-crypt)

**Encryption in Transit**:
```yaml
database:
  ssl_mode: require
  ssl_cert: /path/to/client-cert.pem
  ssl_key: /path/to/client-key.pem
  ssl_root_cert: /path/to/ca-cert.pem
```

### 8.3 Sensitive Data

**PII Fields**: None (no personally identifiable information in orders table)

**Financial Data**:
- `quantity`, `price`, `execution_price` - Consider encryption for regulatory compliance

**Audit Logging**:
```sql
-- Enable audit logging for orders table
CREATE EXTENSION IF NOT EXISTS pgaudit;
ALTER DATABASE hub_order_service SET pgaudit.log = 'write';
```

---

## 9. Monitoring and Alerting

### 9.1 Database Metrics

**Key Metrics**:
1. **Connection Pool**:
   - Active connections
   - Idle connections
   - Connection wait time

2. **Query Performance**:
   - Slow queries (>100ms)
   - Query throughput (queries/sec)
   - Transaction rate

3. **Table Statistics**:
   - Row count
   - Table size
   - Index usage

4. **Replication Lag** (if using replicas):
   - Lag time (seconds)
   - Bytes behind master

### 9.2 Alerts

**Critical Alerts**:
- Connection pool exhausted (>90% utilization)
- Slow queries (>1 second)
- Database down (connection failure)
- Replication lag (>30 seconds)
- Disk space (>80% utilization)

**Warning Alerts**:
- Connection pool high (>70% utilization)
- Slow queries (>500ms)
- Table size growth (>10% per day)
- Index bloat (>50%)

---

## 10. Migration Checklist

### Pre-Migration
- [ ] Create new database: `hub_order_service`
- [ ] Create database user with appropriate permissions
- [ ] Run schema migration (create tables, indexes, triggers)
- [ ] Copy existing orders from monolith database
- [ ] Verify data integrity (row counts, checksums)
- [ ] Test database connection from microservice
- [ ] Configure connection pooling
- [ ] Set up monitoring and alerting

### During Migration
- [ ] Enable dual-write (monolith writes to both databases)
- [ ] Monitor data consistency
- [ ] Test microservice with new database
- [ ] Gradual traffic shift (5% → 10% → 25% → 50% → 100%)
- [ ] Monitor performance metrics

### Post-Migration
- [ ] Disable dual-write (microservice is primary)
- [ ] Monitor for 30 days
- [ ] Verify no data loss or inconsistencies
- [ ] Drop orders table from monolith database (after validation)
- [ ] Update documentation
- [ ] Archive migration scripts

---

## 11. Key Findings and Recommendations

### 11.1 Schema Quality Assessment

✅ **Well-Designed Schema**:
- Proper data types (UUID, DECIMAL, TIMESTAMP)
- Comprehensive constraints (CHECK, NOT NULL)
- Appropriate indexes for common queries
- Auto-updating timestamp trigger

✅ **Good Performance**:
- Composite indexes for common query patterns
- Efficient data types (no bloat)
- Proper normalization

### 11.2 Migration Recommendations

1. **Remove Foreign Key Constraint**: Validate `user_id` via User Service API
2. **Separate Database**: Use Database Per Service pattern
3. **Copy-and-Sync**: Initial copy + dual-write + cutover
4. **Validation Period**: 30 days before decommissioning monolith table
5. **Partitioning**: Plan for future partitioning (when >1M rows)

### 11.3 Critical Success Factors

1. **Data Integrity**: Zero data loss during migration
2. **Foreign Key Handling**: Application-level validation via User Service
3. **Performance**: Maintain current query performance
4. **Rollback Plan**: Tested and documented rollback procedure
5. **Monitoring**: Comprehensive database monitoring in place

---

## 12. Next Steps

- [x] **Step 1.1**: Deep Code Analysis ✅
- [x] **Step 1.2**: Database Schema Analysis (THIS DOCUMENT) ✅
- [ ] **Step 1.3**: Dependency Analysis

---

**Document Status**: ✅ COMPLETE  
**Database**: PostgreSQL  
**Migration Strategy**: Separate Database (Database Per Service Pattern)  
**Foreign Key Impact**: CRITICAL (user_id references users table in User Service)  
**Data Volume**: ~60,000 rows (~36 MB)  
**Estimated Migration Time**: 2-3 days (including validation)

